{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import collections\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from used_metric import get_performance\n",
    "\n",
    "r_path = './douban/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, path=r_path, batch_size = 2048, step = 100):\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.step = step\n",
    "        self.n_users, self.n_items = 0, 0\n",
    "        self.train_user_list = collections.defaultdict(list)\n",
    "        self.train_user_list_time = collections.defaultdict(list)\n",
    "        self.train_item_list = collections.defaultdict(list)\n",
    "        \n",
    "        self.test_user_list = collections.defaultdict(list)\n",
    "        self.test_item_list = collections.defaultdict(list)\n",
    "        \n",
    "        self.load_train_data()\n",
    "        self.load_test_data()\n",
    "        \n",
    "        self.n_users = self.n_users + 1\n",
    "        self.n_items = self.n_items + 1\n",
    "        self.users = list(range(self.n_users))\n",
    "        self.items = list(range(self.n_items))\n",
    "        \n",
    "        self.length = self.batch_size * self.step\n",
    "        \n",
    "    def add_expo_popularity(self,popularity):\n",
    "        self.expo_popularity = popularity\n",
    "        \n",
    "    def load_train_data(self):          \n",
    "        train_file = self.path + 'train_with_time.txt'        \n",
    "        train_data = pd.read_csv(train_file, header=None, sep=' ')\n",
    "        train_data.columns = ['uid','iid','time','stars']\n",
    "        train_data = train_data[['uid','iid','time']]\n",
    "        unique_time = train_data['time'].unique()\n",
    "        print(\"time slot unique in train:\",unique_time)\n",
    "        self.unique_times = list(unique_time)\n",
    "        if train_data['time'].unique().shape[0] < 2:\n",
    "            raise RuntimeWarning(\"there only one time slot for train...., this may cause our method not work\")\n",
    "\n",
    "        for col in train_data.columns:\n",
    "            train_data[col] = train_data[col].astype(int)\n",
    "        user_item_time = train_data.groupby('uid')[['iid','time']].agg(list)\n",
    "        self.train_user_list = dict(zip(user_item_time.index,user_item_time['iid']))\n",
    "        self.train_user_list_time = dict(zip(user_item_time.index,user_item_time['time']))\n",
    "        item_user = train_data.groupby('iid')[['uid','time']].agg(list)\n",
    "        print(item_user.head(2))\n",
    "        self.train_item_list = dict(zip(item_user.index,item_user['uid']))\n",
    "\n",
    "        self.n_users = max(self.n_users,train_data['uid'].max())\n",
    "        self.n_items = max(self.n_items,train_data['iid'].max())\n",
    "        \n",
    "    def load_test_data(self):\n",
    "        test_file = self.path + 'test.txt'\n",
    "        with open(test_file) as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip('\\n').split(' ')\n",
    "                if len(line) == 0:\n",
    "                    continue\n",
    "                line = [int(i) for i in line]\n",
    "                user = line[0]\n",
    "                items = line[1:]\n",
    "                if (len(items)==0):\n",
    "                    continue\n",
    "                self.test_user_list[user] = items\n",
    "                for item in items:\n",
    "                    self.test_item_list[item].append(user)\n",
    "                self.n_users = max(self.n_users, user)\n",
    "                self.n_items = max(self.n_items, max(items))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user = random.choice(self.users) \n",
    "\n",
    "        neg_item = None\n",
    "        \n",
    "        pos_items = self.train_user_list[user]\n",
    "        clicked_times = self.train_user_list_time[user]\n",
    "        \n",
    "        random_index = rd.randint(0,len(pos_items) - 1)\n",
    "        pos_item = pos_items[random_index]\n",
    "        pos_time = clicked_times[random_index]\n",
    "    \n",
    "        while neg_item is None or neg_item in pos_items:\n",
    "            neg_item = rd.choice(self.items)\n",
    "      \n",
    "        pos_pop = self.expo_popularity[pos_item,pos_time]\n",
    "        neg_pop = self.expo_popularity[neg_item,pos_time]   \n",
    "    \n",
    "        return user, pos_item, neg_item, pos_pop, neg_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluation():\n",
    "    def __init__(self, data, Ks, batch_size, popularity):\n",
    "        self.data = data\n",
    "        self.Ks = Ks\n",
    "        self.batch_size = batch_size\n",
    "        self.testing_popularity = popularity\n",
    "\n",
    "    def test_one_batch(self, model, batch_user, pos_pop):\n",
    "        batch_user = batch_user.to(device)\n",
    "        pos_pop = pos_pop.to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_rec = model.do_recommendation(batch_user,pos_pop)\n",
    "        batch_rec = torch.sigmoid(batch_rec)\n",
    "        mask = torch.ones_like(batch_rec)\n",
    "        for i in range(len(batch_user)):\n",
    "            mask[i].scatter_(dim = 0, index=torch.tensor(list(self.data.train_user_list[batch_user[i].item()])).to(device), value=torch.tensor(0.0).to(device))\n",
    "        batch_rec = torch.mul(mask, batch_rec)\n",
    "        _, batch_rec = torch.sort(batch_rec, descending=True)\n",
    "        batch_rec = batch_rec.cpu().numpy()\n",
    "        result = {'precision': np.zeros(len(self.Ks)), 'recall': np.zeros(len(self.Ks)), 'ndcg': np.zeros(len(self.Ks)),\n",
    "                  'hit_ratio': np.zeros(len(self.Ks))}\n",
    "        for i in range(len(batch_user)):\n",
    "            u = batch_user[i].item()\n",
    "            r = batch_rec[i]\n",
    "            u_target = self.data.test_user_list[u]\n",
    "            one_user_result = get_performance(u_target, r, self.Ks)\n",
    "            result['precision'] += one_user_result['precision']\n",
    "            result['recall'] += one_user_result['recall']\n",
    "            result['ndcg'] += one_user_result['ndcg']\n",
    "            result['hit_ratio'] += one_user_result['hit_ratio']\n",
    "        return result\n",
    "\n",
    "    def eval(self, model):\n",
    "        result = {'precision': np.zeros(len(self.Ks)), 'recall': np.zeros(len(self.Ks)), 'ndcg': np.zeros(len(self.Ks)),\n",
    "                  'hit_ratio': np.zeros(len(self.Ks))}\n",
    "        all_users = list(self.data.test_user_list.keys())\n",
    "        tot_users = len(all_users)\n",
    "        for i in range(0, tot_users, self.batch_size):\n",
    "            end_idx = min(i + self.batch_size, tot_users)\n",
    "            batch_user = torch.tensor(all_users[i:end_idx], dtype=torch.long)\n",
    "            pos_pop = torch.from_numpy(self.testing_popularity)\n",
    "            res = self.test_one_batch(model, batch_user, pos_pop)\n",
    "            \n",
    "            result['precision'] += res['precision']/tot_users\n",
    "            result['recall'] += res['recall']/tot_users\n",
    "            result['ndcg'] += res['ndcg']/tot_users\n",
    "            result['hit_ratio'] += res['hit_ratio']/tot_users\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_popularity():\n",
    "    pop_save_path = r_path + \"item_pop_seq_ori2.txt\"\n",
    "    print(\"popularity used:\",pop_save_path)\n",
    "    with open(pop_save_path) as f:\n",
    "        print(\"pop save path: \", pop_save_path)\n",
    "        item_list = []\n",
    "        pop_item_all = []\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            item, pop_list = int(line[0]), [float(x) for x in line[1:]]\n",
    "            item_list.append(item)\n",
    "            pop_item_all.append(pop_list)\n",
    "    pop_item_all = np.array(pop_item_all)\n",
    "    print(\"pop_item_all shape:\", pop_item_all.shape)\n",
    "    print(\"load pop information:\",pop_item_all.mean(),pop_item_all.max(),pop_item_all.min())\n",
    "    return pop_item_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity used: ./autodl-tmp/douban_movie/item_pop_seq_ori2.txt\n",
      "pop save path:  ./autodl-tmp/douban_movie/item_pop_seq_ori2.txt\n",
      "pop_item_all shape: (26047, 10)\n",
      "load pop information: 0.0037181866982990796 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pop_item_all = load_popularity()\n",
    "last_stage_popualarity = pop_item_all[:,-2]\n",
    "popularity_exp = 0.22\n",
    "last_stage_popualarity = np.power(last_stage_popualarity,popularity_exp)   # laste stage popularity (method (a) )\n",
    "\n",
    "linear_predict_popularity = pop_item_all[:,-2] + 0.5 * (pop_item_all[:,-2] - pop_item_all[:,-3]) # linear predicted popularity (method (b))\n",
    "linear_predict_popularity[np.where(linear_predict_popularity<=0)] = 1e-9\n",
    "linear_predict_popularity[np.where(linear_predict_popularity>1.0)] = 1.0\n",
    "linear_predict_popularity = np.power(linear_predict_popularity,popularity_exp) # pop^(gamma) in paper\n",
    "\n",
    "popularity_matrix = pop_item_all[:,:-1]\n",
    "popularity_matrix = np.power(popularity_matrix,popularity_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalBPRMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_size, weight_decay):\n",
    "        super(ConditionalBPRMF, self).__init__()\n",
    "        self.n_users = data.n_users\n",
    "        self.n_items = data.n_items\n",
    "\n",
    "        self.decay = weight_decay\n",
    "        self.emb_dim = emb_size\n",
    "\n",
    "        self.user_embedding = nn.Embedding(self.n_users, self.emb_dim)\n",
    "        self.item_embedding = nn.Embedding(self.n_items, self.emb_dim) \n",
    "        \n",
    "        self.user_embedding.weight.data.uniform_(0, 0.005)  # 0-0.05之间均匀分布\n",
    "        self.user_embedding.weight.data.uniform_(0, 0.005)\n",
    "    \n",
    "    def forward(self, users, pos_items, neg_items, pos_pop, neg_pop):\n",
    "        user_embedding = self.user_embedding(users)\n",
    "        pos_item_embedding = self.item_embedding(pos_items)\n",
    "        neg_item_embedding = self.item_embedding(neg_items)\n",
    "\n",
    "        pos_scores = torch.sum(user_embedding * pos_item_embedding, dim=1)\n",
    "        neg_scores = torch.sum(user_embedding * neg_item_embedding, dim=1)\n",
    "\n",
    "        pos_scores = torch.nn.functional.elu(pos_scores) + 1\n",
    "        neg_scores = torch.nn.functional.elu(neg_scores) + 1\n",
    "        pos_scores_with_pop = pos_scores * pos_pop\n",
    "        neg_scores_with_pop = neg_scores * neg_pop\n",
    "\n",
    "        bpr_loss = -torch.mean(torch.log(torch.sigmoid(pos_scores_with_pop - neg_scores_with_pop)))\n",
    "        \n",
    "        regularizer = torch.norm(user_embedding, p=2) + torch.norm(pos_item_embedding, p=2) + torch.norm(neg_item_embedding, p=2)\n",
    "        reg_loss = self.decay * regularizer\n",
    "        return bpr_loss + reg_loss\n",
    "                    \n",
    "    def do_recommendation(self, users, pos_pop):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_embs = self.item_embedding.weight\n",
    "        scores = torch.mm(user_emb, item_embs.t())\n",
    "        condition_ratings = (torch.nn.functional.elu(scores) + 1) * pos_pop\n",
    "        return condition_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time slot unique in train: [0 1 2 5 3 4 6 7 8]\n",
      "                                                   uid  \\\n",
      "iid                                                      \n",
      "0    [0, 3, 6, 10, 11, 16, 20, 22, 25, 28, 30, 32, ...   \n",
      "1    [0, 1, 40, 60, 80, 83, 91, 106, 108, 114, 124,...   \n",
      "\n",
      "                                                  time  \n",
      "iid                                                     \n",
      "0    [0, 0, 8, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
      "1    [0, 7, 0, 0, 7, 4, 7, 6, 1, 7, 1, 3, 2, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "data = Data(batch_size = 2048, step = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.add_expo_popularity(popularity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(data, batch_size=2048, shuffle=False, num_workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluation(data,[20], 2048, linear_predict_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalBPRMF(data.n_users, data.n_items, emb_size = 32, weight_decay = 1e-04).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 400, loss: 51.14747687125924\n",
      "{'precision': array([0.04942406]), 'recall': array([0.05197279]), 'ndcg': array([0.06543521]), 'hit_ratio': array([0.42218605])}\n",
      "Running time: 2138.6399735584855 Seconds\n",
      "\n",
      "epoch: 410, loss: 51.15021667773258\n",
      "{'precision': array([0.04981845]), 'recall': array([0.05217803]), 'ndcg': array([0.06526828]), 'hit_ratio': array([0.42362589])}\n",
      "Running time: 70.68977475911379 Seconds\n",
      "\n",
      "epoch: 420, loss: 50.657941774938436\n",
      "{'precision': array([0.04979341]), 'recall': array([0.05162756]), 'ndcg': array([0.06712485]), 'hit_ratio': array([0.42325028])}\n",
      "Running time: 68.17763522267342 Seconds\n",
      "\n",
      "epoch: 430, loss: 51.016720747948305\n",
      "{'precision': array([0.04997809]), 'recall': array([0.05202552]), 'ndcg': array([0.06544142]), 'hit_ratio': array([0.42506573])}\n",
      "Running time: 67.34729725122452 Seconds\n",
      "\n",
      "epoch: 440, loss: 50.693308683923775\n",
      "{'precision': array([0.04953988]), 'recall': array([0.05190872]), 'ndcg': array([0.06606868]), 'hit_ratio': array([0.42293727])}\n",
      "Running time: 67.68429540097713 Seconds\n",
      "\n",
      "epoch: 450, loss: 51.0262366070806\n",
      "{'precision': array([0.04984037]), 'recall': array([0.05174798]), 'ndcg': array([0.06575766]), 'hit_ratio': array([0.42437711])}\n",
      "Running time: 67.58547943085432 Seconds\n",
      "\n",
      "epoch: 460, loss: 50.88689281784766\n",
      "{'precision': array([0.05036935]), 'recall': array([0.05343933]), 'ndcg': array([0.06595723]), 'hit_ratio': array([0.42825842])}\n",
      "Running time: 67.43775802850723 Seconds\n",
      "\n",
      "epoch: 470, loss: 50.74856536200195\n",
      "{'precision': array([0.05001565]), 'recall': array([0.05127807]), 'ndcg': array([0.06567187]), 'hit_ratio': array([0.42350069])}\n",
      "Running time: 67.36742800474167 Seconds\n",
      "\n",
      "epoch: 480, loss: 50.728389317615985\n",
      "{'precision': array([0.05181232]), 'recall': array([0.054229]), 'ndcg': array([0.06847701]), 'hit_ratio': array([0.43201452])}\n",
      "Running time: 67.54859086126089 Seconds\n",
      "\n",
      "epoch: 490, loss: 50.776377569264056\n",
      "{'precision': array([0.05075748]), 'recall': array([0.05293171]), 'ndcg': array([0.06749853]), 'hit_ratio': array([0.43076249])}\n",
      "Running time: 66.77045257389545 Seconds\n",
      "\n",
      "epoch: 500, loss: 50.681643299457676\n",
      "{'precision': array([0.05067923]), 'recall': array([0.05310703]), 'ndcg': array([0.06690217]), 'hit_ratio': array([0.42951045])}\n",
      "Running time: 67.07492113858461 Seconds\n",
      "\n",
      "epoch: 510, loss: 50.76840415090892\n",
      "{'precision': array([0.05104858]), 'recall': array([0.05357779]), 'ndcg': array([0.0695744]), 'hit_ratio': array([0.43038688])}\n",
      "Running time: 66.65867038071156 Seconds\n",
      "\n",
      "epoch: 520, loss: 50.54339149259841\n",
      "{'precision': array([0.05077626]), 'recall': array([0.0526979]), 'ndcg': array([0.06772168]), 'hit_ratio': array([0.42825842])}\n",
      "Running time: 68.5272967517376 Seconds\n",
      "\n",
      "epoch: 530, loss: 50.57751970211758\n",
      "{'precision': array([0.05077313]), 'recall': array([0.0532155]), 'ndcg': array([0.06688292]), 'hit_ratio': array([0.43032428])}\n",
      "Running time: 67.19150505959988 Seconds\n",
      "\n",
      "epoch: 540, loss: 50.47653557494659\n",
      "{'precision': array([0.05094529]), 'recall': array([0.05278263]), 'ndcg': array([0.06688857]), 'hit_ratio': array([0.43257794])}\n",
      "Running time: 68.18743769824505 Seconds\n",
      "\n",
      "epoch: 550, loss: 50.5734874767794\n",
      "{'precision': array([0.05104858]), 'recall': array([0.05335294]), 'ndcg': array([0.06764406]), 'hit_ratio': array([0.43245274])}\n",
      "Running time: 67.67375759780407 Seconds\n",
      "\n",
      "epoch: 560, loss: 50.38906249227035\n",
      "{'precision': array([0.05098911]), 'recall': array([0.05391028]), 'ndcg': array([0.06862218]), 'hit_ratio': array([0.43251534])}\n",
      "Running time: 68.92546210438013 Seconds\n",
      "\n",
      "epoch: 570, loss: 50.47957936811962\n",
      "{'precision': array([0.05123638]), 'recall': array([0.05278941]), 'ndcg': array([0.06803439]), 'hit_ratio': array([0.43001127])}\n",
      "Running time: 67.65206497907639 Seconds\n",
      "\n",
      "epoch: 580, loss: 50.29480588867529\n",
      "{'precision': array([0.05112683]), 'recall': array([0.0530855]), 'ndcg': array([0.06814114]), 'hit_ratio': array([0.43038688])}\n",
      "Running time: 67.41385294497013 Seconds\n",
      "\n",
      "epoch: 590, loss: 50.3885083472627\n",
      "{'precision': array([0.05065732]), 'recall': array([0.05255805]), 'ndcg': array([0.06826694]), 'hit_ratio': array([0.42600476])}\n",
      "Running time: 67.2390225827694 Seconds\n",
      "\n",
      "epoch: 600, loss: 50.4346811299449\n",
      "{'precision': array([0.05053211]), 'recall': array([0.05310663]), 'ndcg': array([0.06686949]), 'hit_ratio': array([0.43038688])}\n",
      "Running time: 68.02885501086712 Seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "EPOCH = 600\n",
    "for epoch in range(EPOCH):\n",
    "    t_loss = 0.0\n",
    "    for idx, (users, pos_items, neg_items, pos_pop, neg_pop) in enumerate(dataloader):\n",
    "        users = users.to(device)\n",
    "        pos_items = pos_items.to(device)\n",
    "        neg_items = neg_items.to(device)\n",
    "        pos_pop = pos_pop.to(device)\n",
    "        neg_pop = neg_pop.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(users, pos_items, neg_items, pos_pop, neg_pop)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item()\n",
    "        \n",
    "    if (1+epoch) % 10 == 0 and (1+epoch) >= 400:\n",
    "        res = evaluator.eval(model)\n",
    "        print(f'epoch: {epoch+1}, loss: {t_loss}')\n",
    "        print(res)\n",
    "        end = time.perf_counter()\n",
    "        print('Running time: %s Seconds\\n' % (end - start))\n",
    "        start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
